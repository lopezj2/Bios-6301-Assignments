---
title: "Assignment 1"
author: "James Lopez"
date: "October 11, 2016"
output: pdf_document
---

```{r Create a Data Set}
gender <- c('M','M','F','M','F','F','M','F','M')
age <- c(34, 64, 38, 63, 40, 73, 27, 51, 47)
smoker <- c('no','yes','no','no','yes','no','no','no','yes')
exercise <- factor(c('moderate','frequent','some','some','moderate','none','none','moderate','moderate'),
                   levels=c('none','some','moderate','frequent'), ordered=TRUE
)
los <- c(4,8,1,10,6,3,9,4,8)
x <- data.frame(gender, age, smoker, exercise, los)
x
```


```{r Create a Model}
lm(los ~ gender + age + smoker + exercise, dat=x)
```

##1. Looking at the output, which coefficient seems to have the highest effect on los? 

Gender seems to have the highest influence on 'los' since its coefficient when gender = 'M' has the highest absolute value (4.508675) among the other coefficients

##2. Create a model using los and gender and assign it to the variable mod. Run the summary function with mod as its argument.

```{r}
mod <- lm(los~gender, dat=x)
summary(mod)
```

##3. What is the estimate for the intercept? What is the estimate for gender? Use the coef function. 
```{r Estimates for Intercept and Gender}
coef(mod)
coef(summary(mod))

#The estimates for the Intercept and gender are 3.5 and 4.3, respectively.
```

##4. The second column of coef are standard errors. These can be calculated by taking the sqrt of the diag of the vcov of the summary of mod. Calculate the standard errors.
```{r Standard Errors}
sqrt(diag(vcov(summary(mod))))
#The standard errors of the Intercept and genderM are 1.098701 and 1.474061, respectively.
```

```{r The third column of coef are test statistics. These can be calculated by dividing the first column by the second column.}
mod.c <- coef(summary(mod))
mod.c[,1]/mod.c[,2]
```

##5.Use the pt function to calculate the p value for gender. The first argument should be the test statistic for gender. The second argument is the degrees-of-freedom. Also, set the lower.tail argument to FALSE. Finally multiple this result by two.
```{r P value for Gender}
2*pt(mod.c[2,3],7,lower.tail=FALSE)

#To find the t-statistic for gender, I called the 2nd row, 3rd column element of mod.c, which corresponds to the t-stat. of genderM
```

```{r The estimates can be used to create predicted values.}
3.5+(x$gender=='M')*4.3
```

##6. It is even easier to see the predicted values by passing the model mod to the predict or fitted functions. Try it out. 
```{r Predicted and Fitted values}
predict(mod)
fitted(mod)
```

##7. Predict can also use a new data set. Pass newdat as the second argument to predict.
```{r Newdat}
newdat <- data.frame(gender=c('F','M','F'))
predict(mod,newdat)
```

##8. Use one of the methods to generate predicted values. Subtract the predicted value from the x$los column.
```{r}
x$los-predict(mod)
```

##9. Try passing mod to the residuals function.
```{r}
residuals(mod)
```

##10. Square the residuals, and then sum these values. Compare this to the result of passing mod to the deviance function.
```{r}
sum((residuals(mod))^2)
deviance(mod)
#The two values are the same.
```

```{r Remember that our model object has two items in the formula, los and gender. The residual degrees-of-freedom is the number of observations minus the number of items to account for in the model formula. This can be seen by passing mod to the function df.residual}

df.residual(mod)
```


##11. Calculate standard error by dividing the deviance by the degrees-of-freedom, and then taking the square root. Verify that this matches the output labeled "Residual standard error" from summary(mod).
```{r}
sqrt(deviance(mod)/df.residual(mod))
summary(mod)
```

```{r Note it will also match this output:}
predict(mod,se.fit=TRUE)$residual.scale
```

##12. Create a subset of x by taking all records where gender is 'M' and assigning it to the variable men. Do the same for the variable women.
```{r}
men <- subset(x, gender =='M')
women <- subset(x, gender == 'F')
men
women
```

##13.By default a two-sampled t-test assumes that the two groups have unequal variances. You can calculate variance with the var function. Calculate variance for los for the men and women data sets. 
```{r}
var(men$los)
var(women$los)
```

##14.Call the t.test function, where the first argument is los for women and the second argument is los for men. Call it a second time by adding the argument var.equal and setting it to TRUE. Does either produce output that matches the p value for gender from the model summary? 
```{r}
t.test(women$los, men$los)
t.test(women$los, men$los, var.equal = TRUE)
summary(mod)
#The two-sample t test when var.equal = TRUE produces the same p value for gender from the model summary.
```

```{r An alternative way to call t.test is to use a formula}
t.test(los~gender, dat=x, var.equal=TRUE)
#this t.test produces the same p value for gender as the previous t.test when var.equal=TRUE
t.test(los~gender, dat=x, var.equal=TRUE)$p.value
coef(summary(lm(los~gender, dat=x)))[2,4]
```